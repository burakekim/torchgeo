{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d98c3078-e347-43b3-8944-315da68f6f30",
   "metadata": {},
   "source": [
    "## Land Cover Classification: Sentinel-2 with Cropland Data Layer Annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf35e78-47ea-4c0c-ac80-a7dd057e2032",
   "metadata": {},
   "source": [
    "This tutorial will walk you through the process of performing land cover classification with Sentinel-2 satellite imagery, annotated with CDL (Cropland Data Layer), using TorchGeo library. We will start with downloading Sentinel-2 data, setting it up with CDL for pixel-wise supervised classification, training a segmentation model, and finally running inference to make sense of Sentinel-2 imagery. \n",
    "\n",
    "Whether you are a remote sensing enthusiast or just curious about deep learning for geospatial data, this guide has something cool for you!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "64fc3dad-6908-4b2c-b714-26b2d6a02722",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import planetary_computer\n",
    "import pystac\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchgeo.datasets import RasterDataset\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (12, 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f57a359-5351-4b3a-8ce6-b3e582f395a3",
   "metadata": {},
   "source": [
    "### 1- Downloading Sentinel-2 Imagery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2b7d63-d081-4a8d-b936-b5fdf7d0113a",
   "metadata": {},
   "source": [
    "Fetch Sentinel-2 imagery using Microsoft Planetary Computer and ensure you have the data you need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af9815f",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"/data/sentinel\"\n",
    "item_urls = [\n",
    "    'https://planetarycomputer.microsoft.com/api/stac/v1/collections/sentinel-2-l2a/items/S2B_MSIL2A_20241101T170349_R069_T15TWG_20241101T204038',\n",
    "]\n",
    "\n",
    "for item_url in item_urls:\n",
    "    item = pystac.Item.from_file(item_url)\n",
    "    signed_item = planetary_computer.sign(item)\n",
    "    for band in ['B02', 'B03', 'B04', 'B08']:\n",
    "        asset_href = signed_item.assets[band].href\n",
    "        filename = urlparse(asset_href).path.split('/')[-1]\n",
    "        download_url(asset_href, root, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c64ded-bea4-4dcc-aefe-104cc57a0e74",
   "metadata": {},
   "source": [
    "### 2-  Prepare Dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbdcb27b",
   "metadata": {},
   "source": [
    "Customize TorchGeo to align `Sentinel2` and `CDL` datasets, forming an `IntersectionDataset` for pixel-wise classification task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e88380a5-0a47-4ace-8171-657a9d688164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting CDL res from 0.000325900410757084 to 10\n",
      "Converting CDL res from 0.000325900410757084 to 10\n",
      "Converting CDL res from 0.000325900410757084 to 10\n"
     ]
    }
   ],
   "source": [
    "from torchgeo.datasets import Sentinel2\n",
    "\n",
    "class Sentinel2Custom(Sentinel2):\n",
    "    filename_glob = 'T*_B02_10m.tif'\n",
    "    filename_regex = r'.*'\n",
    "    date_format = '%Y%m%dT%H%M%S'\n",
    "    is_image = True\n",
    "    separate_files = True\n",
    "    all_bands = ('B02', 'B03', 'B04', 'B08')\n",
    "    rgb_bands = ('B04', 'B03', 'B02')\n",
    "\n",
    "import torchgeo.datasets\n",
    "torchgeo.datasets.Sentinel2 = Sentinel2Custom\n",
    "\n",
    "from torchgeo.datamodules import Sentinel2CDLDataModule\n",
    "\n",
    "datamodule = Sentinel2CDLDataModule(\n",
    "    cdl_crs=\"epsg:4326\",\n",
    "    sentinel2_crs=\"epsg:4326\",\n",
    "    cdl_paths=\"/data/datatorchgeo\",\n",
    "    sentinel2_paths=\"/data/sentinel\",\n",
    "    batch_size=1,\n",
    "    patch_size=64,\n",
    "    length=8\n",
    ")\n",
    "\n",
    "datamodule.setup(\"fit\")\n",
    "train_dataset = datamodule.train_dataset\n",
    "datamodule.setup(\"validate\")\n",
    "val_dataset = datamodule.val_dataset\n",
    "datamodule.setup(\"test\")\n",
    "test_dataset = datamodule.test_dataset\n",
    "\n",
    "datamodule.val_sampler.length = 3\n",
    "datamodule.test_sampler.length = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d485655d-ea8b-41c1-a10d-5a62bf0ed24a",
   "metadata": {},
   "source": [
    "### 3- Training Semantic Segmentation Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6697dde8-fce2-4cc1-b661-7efc3c879307",
   "metadata": {},
   "source": [
    "Train a UNet model with Sentinel-2 images paired with CDL labels to classify land cover, powered by PyTorch Lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c2d929e3-4898-47e8-83a1-d7d110dcf42a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "INFO: GPU available: True (cuda), used: True\n",
      "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
      "INFO: TPU available: False, using: 0 TPU cores\n",
      "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO: IPU available: False, using: 0 IPUs\n",
      "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
      "INFO: HPU available: False, using: 0 HPUs\n",
      "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
      "INFO: Running in `fast_dev_run` mode: will run the requested loop using 1 batch(es). Logging and checkpointing is suppressed.\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Running in `fast_dev_run` mode: will run the requested loop using 1 batch(es). Logging and checkpointing is suppressed.\n",
      "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "INFO: \n",
      "  | Name          | Type             | Params\n",
      "---------------------------------------------------\n",
      "0 | model         | Unet             | 32.5 M\n",
      "1 | criterion     | CrossEntropyLoss | 0     \n",
      "2 | train_metrics | MetricCollection | 0     \n",
      "3 | val_metrics   | MetricCollection | 0     \n",
      "4 | test_metrics  | MetricCollection | 0     \n",
      "---------------------------------------------------\n",
      "32.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "32.5 M    Total params\n",
      "130.162   Total estimated model params size (MB)\n",
      "INFO:lightning.pytorch.callbacks.model_summary:\n",
      "  | Name          | Type             | Params\n",
      "---------------------------------------------------\n",
      "0 | model         | Unet             | 32.5 M\n",
      "1 | criterion     | CrossEntropyLoss | 0     \n",
      "2 | train_metrics | MetricCollection | 0     \n",
      "3 | val_metrics   | MetricCollection | 0     \n",
      "4 | test_metrics  | MetricCollection | 0     \n",
      "---------------------------------------------------\n",
      "32.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "32.5 M    Total params\n",
      "130.162   Total estimated model params size (MB)\n",
      "/opt/conda/envs/ood/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=63` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting CDL res from 0.000325900410757084 to 10\n"
     ]
    },
    {
     "ename": "MisconfigurationException",
     "evalue": "Sentinel2CDLDataModule.val_sampler has length 0.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMisconfigurationException\u001b[0m                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 31\u001b[0m\n\u001b[1;32m     20\u001b[0m accelerator \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpu\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     22\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     23\u001b[0m     accelerator\u001b[38;5;241m=\u001b[39maccelerator,\n\u001b[1;32m     24\u001b[0m     default_root_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     28\u001b[0m     max_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m     29\u001b[0m )\n\u001b[0;32m---> 31\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatamodule\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/ood/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py:544\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    542\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[1;32m    543\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 544\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    545\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    546\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/ood/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py:44\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     43\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     47\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[0;32m/opt/conda/envs/ood/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py:580\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    574\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    575\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[1;32m    576\u001b[0m     ckpt_path,\n\u001b[1;32m    577\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    578\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    579\u001b[0m )\n\u001b[0;32m--> 580\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[1;32m    583\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/ood/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py:987\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    982\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_signal_connector\u001b[38;5;241m.\u001b[39mregister_signal_handlers()\n\u001b[1;32m    984\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    985\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m    986\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m--> 987\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    989\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    990\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m    991\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    992\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: trainer tearing down\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/envs/ood/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py:1033\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1031\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_sanity_check()\n\u001b[1;32m   1032\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[0;32m-> 1033\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1034\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1035\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnexpected state \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/envs/ood/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py:201\u001b[0m, in \u001b[0;36m_FitLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset()\n\u001b[0;32m--> 201\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_run_start\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone:\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/envs/ood/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py:324\u001b[0m, in \u001b[0;36m_FitLoop.on_run_start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepoch_loop\u001b[38;5;241m.\u001b[39m_should_check_val_epoch() \u001b[38;5;129;01mand\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mval_dataloaders \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    323\u001b[0m     trainer\u001b[38;5;241m.\u001b[39mvalidating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 324\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mval_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    325\u001b[0m     trainer\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    327\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_callback_hooks(trainer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_train_start\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/envs/ood/lib/python3.11/site-packages/lightning/pytorch/loops/evaluation_loop.py:166\u001b[0m, in \u001b[0;36m_EvaluationLoop.setup_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    164\u001b[0m stage \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stage\n\u001b[1;32m    165\u001b[0m source \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_source\n\u001b[0;32m--> 166\u001b[0m dataloaders \u001b[38;5;241m=\u001b[39m \u001b[43m_request_dataloader\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mbarrier(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstage\u001b[38;5;241m.\u001b[39mdataloader_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_dataloader()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dataloaders, CombinedLoader):\n",
      "File \u001b[0;32m/opt/conda/envs/ood/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:342\u001b[0m, in \u001b[0;36m_request_dataloader\u001b[0;34m(data_source)\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Requests a dataloader by calling dataloader hooks corresponding to the given stage.\u001b[39;00m\n\u001b[1;32m    332\u001b[0m \n\u001b[1;32m    333\u001b[0m \u001b[38;5;124;03mReturns:\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03m    The requested dataloader\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _replace_dunder_methods(DataLoader, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m\"\u001b[39m), _replace_dunder_methods(BatchSampler):\n\u001b[1;32m    338\u001b[0m     \u001b[38;5;66;03m# under this context manager, the arguments passed to `DataLoader.__init__` will be captured and saved as\u001b[39;00m\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;66;03m# attributes on the instance in case the dataloader needs to be re-instantiated later by Lightning.\u001b[39;00m\n\u001b[1;32m    340\u001b[0m     \u001b[38;5;66;03m# Also, it records all attribute setting and deletion using patched `__setattr__` and `__delattr__`\u001b[39;00m\n\u001b[1;32m    341\u001b[0m     \u001b[38;5;66;03m# methods so that the re-instantiated object is as close to the original as possible.\u001b[39;00m\n\u001b[0;32m--> 342\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdata_source\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataloader\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/ood/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:309\u001b[0m, in \u001b[0;36m_DataLoaderSource.dataloader\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minstance, pl\u001b[38;5;241m.\u001b[39mLightningDataModule):\n\u001b[1;32m    308\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minstance\u001b[38;5;241m.\u001b[39mtrainer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 309\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_lightning_datamodule_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minstance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minstance \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minstance\n",
      "File \u001b[0;32m/opt/conda/envs/ood/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py:179\u001b[0m, in \u001b[0;36m_call_lightning_datamodule_hook\u001b[0;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(fn):\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[LightningDataModule]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer\u001b[38;5;241m.\u001b[39mdatamodule\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 179\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/ood/lib/python3.11/site-packages/torchgeo/datamodules/geo.py:314\u001b[0m, in \u001b[0;36mGeoDataModule.val_dataloader\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mval_dataloader\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataLoader[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Tensor]]:\n\u001b[1;32m    305\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Implement one or more PyTorch DataLoaders for validation.\u001b[39;00m\n\u001b[1;32m    306\u001b[0m \n\u001b[1;32m    307\u001b[0m \u001b[38;5;124;03m    Returns:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;124;03m            dataset or sampler, or if the dataset or sampler has length 0.\u001b[39;00m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 314\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataloader_factory\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mval\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/ood/lib/python3.11/site-packages/torchgeo/datamodules/geo.py:270\u001b[0m, in \u001b[0;36mGeoDataModule._dataloader_factory\u001b[0;34m(self, split)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Implement one or more PyTorch DataLoaders.\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \n\u001b[1;32m    259\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;124;03m        dataset or sampler, or if the dataset or sampler has length 0.\u001b[39;00m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    269\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_valid_attribute(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msplit\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_dataset\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 270\u001b[0m sampler \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_valid_attribute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43msplit\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_batch_sampler\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43msplit\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_sampler\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbatch_sampler\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msampler\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m    272\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    273\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_valid_attribute(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msplit\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_batch_size\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(sampler, BatchGeoSampler):\n",
      "File \u001b[0;32m/opt/conda/envs/ood/lib/python3.11/site-packages/torchgeo/datamodules/geo.py:111\u001b[0m, in \u001b[0;36mBaseDataModule._valid_attribute\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m obj:\n\u001b[1;32m    110\u001b[0m         msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00marg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m has length 0.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 111\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m MisconfigurationException(msg)\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[1;32m    115\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.setup must define one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[0;31mMisconfigurationException\u001b[0m: Sentinel2CDLDataModule.val_sampler has length 0."
     ]
    }
   ],
   "source": [
    "from torchgeo.trainers import SemanticSegmentationTask\n",
    "from lightning.pytorch import Trainer\n",
    "import torch\n",
    "\n",
    "task = SemanticSegmentationTask(\n",
    "    model='unet',\n",
    "    backbone='resnet50',\n",
    "    weights=None,  # No pre-trained weights\n",
    "    in_channels=3,  # CDL dataset may have RGB inputs\n",
    "    num_classes=134,\n",
    "    num_filters=3,\n",
    "    loss='ce',  # CrossEntropyLoss\n",
    "    class_weights=None,\n",
    "    ignore_index=None,\n",
    "    lr=0.001,\n",
    "    patience=10,\n",
    "    freeze_backbone=False,\n",
    "    freeze_decoder=False)\n",
    "\n",
    "accelerator = 'gpu' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "trainer = Trainer(\n",
    "    accelerator=accelerator,\n",
    "    default_root_dir='./',\n",
    "    fast_dev_run=True,\n",
    "    log_every_n_steps=1,\n",
    "    min_epochs=1,\n",
    "    max_epochs=2,\n",
    ")\n",
    "\n",
    "trainer.fit(model=task, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf8471b-9819-4455-9555-883ca14c02cb",
   "metadata": {},
   "source": [
    "### 4- Model Evaluation on Test Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ff6099-6166-46fd-a17e-8add9f8e66bd",
   "metadata": {},
   "source": [
    "Evaluate the segmentation model over the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc63948-48c8-410a-8138-b52304de95a9",
   "metadata": {},
   "source": [
    "### 5- Inference over full Imagery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba64aa3-225f-4cfd-86e9-e93be5de03d8",
   "metadata": {},
   "source": [
    "Perform inference by computing predictions over the complete imagery "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae874d36-f130-47b6-a3e9-9c83d2bd1f17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0192d35-0616-432e-b40b-3bed570637a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee26d007-4183-4dcd-a58b-a8ae6c886711",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "32e33497-5348-4e3d-87fa-30dd9789a653",
   "metadata": {},
   "source": [
    "### Debug"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674babba-ba03-48cf-9f9d-365c990b7526",
   "metadata": {},
   "source": [
    "self.length = 0 is not populating in gridgeosample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f868bf-af2f-4080-9082-f104f0c21520",
   "metadata": {},
   "source": [
    "self.length = 0\n",
    "self.hits = []\n",
    "areas = []\n",
    "for hit in self.index.intersection(tuple(self.roi), objects=True):\n",
    "    bounds = BoundingBox(*hit.bounds)\n",
    "    if (\n",
    "        bounds.maxx - bounds.minx >= self.size[1]\n",
    "        and bounds.maxy - bounds.miny >= self.size[0]\n",
    "    ):\n",
    "        if bounds.area > 0:\n",
    "            rows, cols = tile_to_chips(bounds, self.size)\n",
    "            self.length += rows * cols\n",
    "        else:\n",
    "            self.length += 1\n",
    "        self.hits.append(hit)\n",
    "        areas.append(bounds.area)\n",
    "if length is not None:\n",
    "    self.length = length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "de4ed9a4-f8df-49e6-8149-931e24035da0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torchgeo.datasets.geo.IntersectionDataset at 0x7fb98493dcd0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datamodule.val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4ac1e7-b592-43f0-be77-fe5351a2f1e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "427b239a-3ae8-43b7-9dc7-56f26f81b13d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52, 6, 6)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset), len(val_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fe9029b-5224-4ff7-8a81-8abfa50a2af4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/data/sentinel/T15TWG_20241101T170349_B02_10m.tif']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datamodule.sentinel2.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b063ee64-ba7b-4a57-8171-b7b83c26a5ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/data/datatorchgeo/2023_30m_cdls.tif']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datamodule.cdl.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e64d788-4c31-4244-ba38-21089f42db0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundingBox(minx=-93.00024322601918, maxx=-91.66508508222715, miny=41.456209388641454, maxy=42.45269119869629, mint=1672531200.0, maxt=1704067199.999999)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datamodule.train_dataset.bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8eec860-23e4-4a5e-8dc8-8a53f4a5565d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundingBox(minx=-93.00024322601918, maxx=-91.66508508222715, miny=41.456209388641454, maxy=42.45269119869629, mint=0.0, maxt=9.223372036854776e+18)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datamodule.sentinel2.bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd6709f3-3424-42a5-aff6-7b61864c3e4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundingBox(minx=-127.88721217969017, maxx=-65.34561975376272, miny=22.94022503977174, maxy=51.60512156832182, mint=1672531200.0, maxt=1704067199.999999)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datamodule.cdl.bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21cc2af8-9294-4309-8f8a-46ea260cc9fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<__main__.Sentinel2Custom at 0x7fb9a2912bd0>,\n",
       " <torchgeo.datasets.cdl.CDL at 0x7fb9a2910f90>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datamodule.train_dataset.datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf55a63-c475-495a-a124-f30acacdf586",
   "metadata": {},
   "source": [
    "### intersection dataset: \n",
    "        self.dataset = self.sentinel2 & self.cdl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a84ecae2-ecf8-4b3a-915f-03c3e28f7e92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torchgeo.datasets.geo.IntersectionDataset at 0x7fb9a28fd8d0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datamodule.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82c12a25-e47f-44d7-a45a-4056b156e601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torchgeo.datasets.geo.IntersectionDataset at 0x7fb9a2912ed0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datamodule.train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "344a02e7-03c3-4011-8ce1-1f0787ef2fbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<torchgeo.datasets.geo.IntersectionDataset at 0x7fb9a2912ed0>, 52, 6, 6)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datamodule.train_dataset, len(datamodule.train_dataset), len(datamodule.val_dataset), len(datamodule.test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ef300ee-af65-4735-900b-21154a495f6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(640, 640)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datamodule.train_batch_sampler.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eaffb54b-461d-49d9-94aa-de96af210b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1792.7482756199618\n"
     ]
    }
   ],
   "source": [
    "from torchgeo.datasets.utils import BoundingBox\n",
    "\n",
    "for i in datamodule.cdl.index.intersection(datamodule.cdl.index.bounds, objects=True):\n",
    "    box1 = BoundingBox(*i.bounds)\n",
    "    print(box1.area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "86fbc6ee-f34a-4862-8705-fdb557658dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3304608038353392\n"
     ]
    }
   ],
   "source": [
    "for i in datamodule.sentinel2.index.intersection(datamodule.sentinel2.index.bounds, objects=True):\n",
    "    box1 = BoundingBox(*i.bounds)\n",
    "    print(box1.area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "43fb640a-c6c6-48a5-9aee-098922eb9457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit1 <rtree.index.Item object at 0x7fb9a291b7e0>\n",
      "box1.area 1792.7482756199618\n",
      "box2.area 1.3304608038353392\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "\n",
    "for hit1 in datamodule.cdl.index.intersection(datamodule.cdl.index.bounds, objects=True):\n",
    "    print(\"hit1\", hit1)\n",
    "    for hit2 in datamodule.sentinel2.index.intersection(hit1.bounds, objects=True):\n",
    "        box1 = BoundingBox(*hit1.bounds)\n",
    "        box2 = BoundingBox(*hit2.bounds)\n",
    "        print(\"box1.area\", box1.area)\n",
    "        print(\"box2.area\", box2.area)\n",
    "        box3 = box1 & box2\n",
    "        # Skip 0 area overlap (unless 0 area dataset)\n",
    "        if box3.area > 0 or box1.area == 0 or box2.area == 0:\n",
    "            # self.index.insert(i, tuple(box3))\n",
    "            i += 1\n",
    "\n",
    "if i == 0:\n",
    "    raise RuntimeError('Datasets have no spatiotemporal intersection')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5b530c-47f7-4a1a-831e-5283c5f59de2",
   "metadata": {},
   "source": [
    "### Debug Sentinel2CDLDataModule.train_batch_sampler has len 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aae0b348-40f9-46d1-a9d6-3c889793cc73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(640, 640)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datamodule.train_batch_sampler.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e88e8a34-f998-466d-a2c0-7077be028dea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<torchgeo.datasets.geo.IntersectionDataset at 0x7fb9a2912ed0>, 64, 1, 8)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datamodule.train_dataset, datamodule.patch_size, datamodule.batch_size, datamodule.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "127fc622-d6a5-43a0-9497-503774b98b30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datamodule.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bd62eb3b-8b17-4602-8806-18f03109ea7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 3, 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(datamodule.train_batch_sampler), len(datamodule.val_sampler), len(datamodule.test_sampler)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "execution": {
   "timeout": 1200
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
