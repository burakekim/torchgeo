{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929fa39f-25a1-4c23-9695-916a6fddae9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) Microsoft Corporation. All rights reserved.\n",
    "# Licensed under the MIT License."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98c3078-e347-43b3-8944-315da68f6f30",
   "metadata": {},
   "source": [
    "## Land Cover Classification: Sentinel-2 with EuroCrops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf35e78-47ea-4c0c-ac80-a7dd057e2032",
   "metadata": {},
   "source": [
    "This tutorial will walk you through the process of performing land cover classification with Sentinel-2 satellite imagery, annotated with EuroCrops, using TorchGeo library. We will start with downloading Sentinel-2 data, setting it up with EuroCrops for pixel-wise supervised classification, training a segmentation model, and finally running inference to make sense of Sentinel-2 imagery. \n",
    "\n",
    "Whether you are a remote sensing enthusiast or just curious about deep learning for geospatial data, this guide has something cool for you!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64fc3dad-6908-4b2c-b714-26b2d6a02722",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import planetary_computer\n",
    "import pystac\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchgeo.datasets.utils import download_url\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (12, 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f57a359-5351-4b3a-8ce6-b3e582f395a3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 1- Downloading Sentinel-2 Imagery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2b7d63-d081-4a8d-b936-b5fdf7d0113a",
   "metadata": {},
   "source": [
    "Fetch Sentinel-2 imagery using Microsoft Planetary Computer and ensure you have the data you need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af9815f",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"/data/sentinel\"\n",
    "item_urls = [\n",
    "    'https://planetarycomputer.microsoft.com/api/stac/v1/collections/sentinel-2-l2a/items/S2A_MSIL2A_20220827T093601_R036_T34UEA_20220829T151158',\n",
    "]\n",
    "for item_url in item_urls:\n",
    "    item = pystac.Item.from_file(item_url)\n",
    "    signed_item = planetary_computer.sign(item)\n",
    "    for band in ['B02', 'B03', 'B04', 'B08']:\n",
    "        asset_href = signed_item.assets[band].href\n",
    "        filename = urlparse(asset_href).path.split('/')[-1]\n",
    "        download_url(asset_href, root, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c64ded-bea4-4dcc-aefe-104cc57a0e74",
   "metadata": {},
   "source": [
    "### 2-  Prepare Dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbdcb27b",
   "metadata": {},
   "source": [
    "Customize TorchGeo to align `Sentinel2` and `EuroCrops` datasets, forming an `IntersectionDataset` for pixel-wise classification task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfb04476-0d0e-48cb-b678-757cbcebe76b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/data/sentinel/T34UEA_20220827T093601_B02_10m.tif']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datamodule.sentinel2.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d6243e0-7a98-4f9e-b015-12c91d3c3802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRS.from_epsg(32634)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datamodule.sentinel2.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ea4878b-90c7-4a0d-a4ec-67d9be38ed35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/data/sentinel/T34UEA_20220827T093601_B02_10m.tif']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datamodule.sentinel2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df173ec5-535c-465d-a37e-b12b755eccaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/data/datatorchgeo/AT_2021/AT_2021_EC21.shp',\n",
       " '/data/datatorchgeo/BE_VLG_2021/BE_VLG_2021_EC21.shp',\n",
       " '/data/datatorchgeo/DE_LS_2021/DE_LS_2021_EC21.shp',\n",
       " '/data/datatorchgeo/DE_NRW_2021/DE_NRW_2021_EC21.shp',\n",
       " '/data/datatorchgeo/DK_2019_EC21.shp',\n",
       " '/data/datatorchgeo/EE_2021_EC21.shp',\n",
       " '/data/datatorchgeo/FR_2018/FR_2018_EC21.shp',\n",
       " '/data/datatorchgeo/HR/HR_2020_EC21.shp',\n",
       " '/data/datatorchgeo/LT_2021_EC.shp',\n",
       " '/data/datatorchgeo/LV_2021/LV_2021_EC21.shp',\n",
       " '/data/datatorchgeo/NA/ES_NA_2020_EC21.shp',\n",
       " '/data/datatorchgeo/NL_2020_EC21.shp',\n",
       " '/data/datatorchgeo/PT_2021_EC21.shp',\n",
       " '/data/datatorchgeo/SE/SE_2021_EC21.shp',\n",
       " '/data/datatorchgeo/SI_2021_EC21.shp',\n",
       " '/data/datatorchgeo/SK_2021_EC21.shp']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datamodule.eurocrops.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "762a318b-bf7d-4912-b74f-251d8433cf00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRS.from_epsg(32634)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datamodule.eurocrops.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69e4181f-3ee2-49e9-b22a-33201b7f5b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule.dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd85674a-f5c5-45fa-9616-4dddd6cda3f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting EuroCrops CRS from EPSG:4326 to EPSG:32634\n",
      "Converting EuroCrops res from 1e-05 to 10\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Datasets have no spatiotemporal intersection",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 32\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchgeo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatamodules\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sentinel2EuroCropsDataModule\n\u001b[1;32m     21\u001b[0m datamodule \u001b[38;5;241m=\u001b[39m Sentinel2EuroCropsDataModule(\n\u001b[1;32m     22\u001b[0m     sentinel2_paths\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/data/sentinel\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     23\u001b[0m     eurocrops_paths\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/data/datatorchgeo\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;66;03m# length=8,\u001b[39;00m\n\u001b[1;32m     30\u001b[0m )\n\u001b[0;32m---> 32\u001b[0m \u001b[43mdatamodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfit\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m datamodule\u001b[38;5;241m.\u001b[39mtrain_dataset\n\u001b[1;32m     34\u001b[0m datamodule\u001b[38;5;241m.\u001b[39msetup(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidate\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/envs/ood/lib/python3.11/site-packages/torchgeo/datamodules/sentinel2_eurocrops.py:90\u001b[0m, in \u001b[0;36mSentinel2EuroCropsDataModule.setup\u001b[0;34m(self, stage)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msentinel2 \u001b[38;5;241m=\u001b[39m Sentinel2(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msentinel2_kwargs)\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meurocrops \u001b[38;5;241m=\u001b[39m EuroCrops(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meurocrops_kwargs)\n\u001b[0;32m---> 90\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msentinel2\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m&\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meurocrops\u001b[49m\n\u001b[1;32m     92\u001b[0m generator \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mGenerator()\u001b[38;5;241m.\u001b[39mmanual_seed(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     93\u001b[0m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_dataset, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mval_dataset, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_dataset) \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     94\u001b[0m     random_grid_cell_assignment(\n\u001b[1;32m     95\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, [\u001b[38;5;241m0.8\u001b[39m, \u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m0.1\u001b[39m], grid_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m, generator\u001b[38;5;241m=\u001b[39mgenerator\n\u001b[1;32m     96\u001b[0m     )\n\u001b[1;32m     97\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/envs/ood/lib/python3.11/site-packages/torchgeo/datasets/geo.py:155\u001b[0m, in \u001b[0;36mGeoDataset.__and__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__and__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGeoDataset\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIntersectionDataset\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    142\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Take the intersection of two :class:`GeoDataset`.\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \n\u001b[1;32m    144\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;124;03m    .. versionadded:: 0.2\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 155\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mIntersectionDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/ood/lib/python3.11/site-packages/torchgeo/datasets/geo.py:989\u001b[0m, in \u001b[0;36mIntersectionDataset.__init__\u001b[0;34m(self, dataset1, dataset2, collate_fn, transforms)\u001b[0m\n\u001b[1;32m    986\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mres \u001b[38;5;241m=\u001b[39m dataset1\u001b[38;5;241m.\u001b[39mres\n\u001b[1;32m    988\u001b[0m \u001b[38;5;66;03m# Merge dataset indices into a single index\u001b[39;00m\n\u001b[0;32m--> 989\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_merge_dataset_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/ood/lib/python3.11/site-packages/torchgeo/datasets/geo.py:1006\u001b[0m, in \u001b[0;36mIntersectionDataset._merge_dataset_indices\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1003\u001b[0m             i \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1005\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 1006\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDatasets have no spatiotemporal intersection\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Datasets have no spatiotemporal intersection"
     ]
    }
   ],
   "source": [
    "from torchgeo.datasets import Sentinel2, RasterDataset\n",
    "\n",
    "class Sentinel2_Custom(Sentinel2):\n",
    "    filename_glob = 'T34UEA_*_{}*.*'\n",
    "    filename_regex = r\"\"\"\n",
    "        ^T(?P<tile>\\d{{2}}[A-Z]{{3}})\n",
    "        _(?P<date>\\d{{8}}T\\d{{6}})\n",
    "        _(?P<band>B[018][\\dA])\n",
    "        (?:_(?P<resolution>{}m))?\n",
    "        \\..*$\n",
    "    \"\"\"\n",
    "    date_format = '%Y%m%dT%H%M%S'\n",
    "    all_bands = ('B02', 'B03', 'B04', 'B08')\n",
    "    rgb_bands = ('B04', 'B03', 'B02')\n",
    "\n",
    "import torchgeo.datasets\n",
    "torchgeo.datasets.Sentinel2 = Sentinel2_Custom\n",
    "\n",
    "from torchgeo.datamodules import Sentinel2EuroCropsDataModule\n",
    "\n",
    "datamodule = Sentinel2EuroCropsDataModule(\n",
    "    sentinel2_paths=\"/data/sentinel\",\n",
    "    eurocrops_paths=\"/data/datatorchgeo\",\n",
    "    batch_size=1,\n",
    "    # eurocrops_crs=\"epsg:4326\",\n",
    "    # sentinel2_crs=\"epsg:4326\",\n",
    "    patch_size=64,\n",
    "    num_workers=32,\n",
    "    # length=8,\n",
    ")\n",
    "\n",
    "datamodule.setup(\"fit\")\n",
    "train_dataset = datamodule.train_dataset\n",
    "datamodule.setup(\"validate\")\n",
    "val_dataset = datamodule.val_dataset\n",
    "datamodule.setup(\"test\")\n",
    "test_dataset = datamodule.test_dataset\n",
    "\n",
    "# datamodule.val_sampler.length = 3\n",
    "# datamodule.test_sampler.length = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40af294d-90a5-45e0-ba68-df0f16e91847",
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule.sentinel2_kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca7c35c-02ea-42bb-ab90-d61ad09177ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sentinel2Custom.is_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8147b20a-1806-4a99-95cd-8c1fac24ba12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "datamodule.eurocrops.class_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58ff9e0-8bb1-49b9-a183-f82dfe5117b0",
   "metadata": {},
   "source": [
    "#### Visualize the Sentinel-2 imagery and EuroCrops Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5873c6a-a427-4d3e-99e9-9fff48bb22bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d485655d-ea8b-41c1-a10d-5a62bf0ed24a",
   "metadata": {},
   "source": [
    "### 3- Training Semantic Segmentation Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6697dde8-fce2-4cc1-b661-7efc3c879307",
   "metadata": {},
   "source": [
    "Train a UNet model with Sentinel-2 images paired with EuroCrops labels to classify land cover, powered by PyTorch Lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d929e3-4898-47e8-83a1-d7d110dcf42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchgeo.trainers import SemanticSegmentationTask\n",
    "from lightning.pytorch import Trainer\n",
    "import torch\n",
    "\n",
    "task = SemanticSegmentationTask(\n",
    "    model='unet',\n",
    "    backbone='resnet50',\n",
    "    weights=None,  # TODO: Add pretrained weights\n",
    "    in_channels=4,\n",
    "    num_classes=396, # TODO: How many classes are there? All countries in the dataset have different number of classes\n",
    "    num_filters=3,\n",
    "    loss='ce', # Either the loss or the f-f' are wrong\n",
    "    class_weights=None,\n",
    "    ignore_index=None,\n",
    "    lr=0.001,\n",
    "    patience=10,\n",
    "    freeze_backbone=False,\n",
    "    freeze_decoder=False)\n",
    "\n",
    "# TODO: Trainer on CPU for now as I could not move 'input' to CUDA \n",
    "# accelerator = 'gpu' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "trainer = Trainer(\n",
    "    accelerator='cpu',\n",
    "    default_root_dir='./',\n",
    "    fast_dev_run=False,\n",
    "    log_every_n_steps=1,\n",
    "    min_epochs=2,\n",
    "    max_epochs=20,\n",
    ")\n",
    "\n",
    "trainer.fit(model=task, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf8471b-9819-4455-9555-883ca14c02cb",
   "metadata": {},
   "source": [
    "### 4- Model Evaluation on Test Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ff6099-6166-46fd-a17e-8add9f8e66bd",
   "metadata": {},
   "source": [
    "Evaluate the segmentation model over the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc63948-48c8-410a-8138-b52304de95a9",
   "metadata": {},
   "source": [
    "### 5- Inference over full Imagery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba64aa3-225f-4cfd-86e9-e93be5de03d8",
   "metadata": {},
   "source": [
    "Perform inference by computing predictions over the complete imagery "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae874d36-f130-47b6-a3e9-9c83d2bd1f17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0192d35-0616-432e-b40b-3bed570637a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee26d007-4183-4dcd-a58b-a8ae6c886711",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427b239a-3ae8-43b7-9dc7-56f26f81b13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_dataset), len(val_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe9029b-5224-4ff7-8a81-8abfa50a2af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule.sentinel2.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b063ee64-ba7b-4a57-8171-b7b83c26a5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule.eurocrops.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e64d788-4c31-4244-ba38-21089f42db0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule.train_dataset.bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8eec860-23e4-4a5e-8dc8-8a53f4a5565d",
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule.sentinel2.bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6709f3-3424-42a5-aff6-7b61864c3e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule.eurocrops.bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21cc2af8-9294-4309-8f8a-46ea260cc9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule.train_dataset.datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84ecae2-ecf8-4b3a-915f-03c3e28f7e92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "datamodule.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c12a25-e47f-44d7-a45a-4056b156e601",
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule.train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344a02e7-03c3-4011-8ce1-1f0787ef2fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule.train_dataset, len(datamodule.train_dataset), len(datamodule.val_dataset), len(datamodule.test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef300ee-af65-4735-900b-21154a495f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule.train_batch_sampler.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaffb54b-461d-49d9-94aa-de96af210b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchgeo.datasets.utils import BoundingBox\n",
    "\n",
    "for i in datamodule.eurocrops.index.intersection(datamodule.eurocrops.index.bounds, objects=True):\n",
    "    box1 = BoundingBox(*i.bounds)\n",
    "    print(box1.area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fbc6ee-f34a-4862-8705-fdb557658dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in datamodule.sentinel2.index.intersection(datamodule.sentinel2.index.bounds, objects=True):\n",
    "    box1 = BoundingBox(*i.bounds)\n",
    "    print(box1.area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fb640a-c6c6-48a5-9aee-098922eb9457",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "\n",
    "for hit1 in datamodule.eurocrops.index.intersection(datamodule.eurocrops.index.bounds, objects=True):\n",
    "    print(\"hit1\", hit1)\n",
    "    for hit2 in datamodule.sentinel2.index.intersection(hit1.bounds, objects=True):\n",
    "        box1 = BoundingBox(*hit1.bounds)\n",
    "        box2 = BoundingBox(*hit2.bounds)\n",
    "        print(\"box1.area\", box1.area)\n",
    "        print(\"box2.area\", box2.area)\n",
    "        box3 = box1 & box2\n",
    "        # Skip 0 area overlap (unless 0 area dataset)\n",
    "        if box3.area > 0 or box1.area == 0 or box2.area == 0:\n",
    "            # self.index.insert(i, tuple(box3))\n",
    "            i += 1\n",
    "\n",
    "if i == 0:\n",
    "    raise RuntimeError('Datasets have no spatiotemporal intersection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae0b348-40f9-46d1-a9d6-3c889793cc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule.train_batch_sampler.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88e8a34-f998-466d-a2c0-7077be028dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule.train_dataset, datamodule.patch_size, datamodule.batch_size, datamodule.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127fc622-d6a5-43a0-9497-503774b98b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd62eb3b-8b17-4602-8806-18f03109ea7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(datamodule.train_batch_sampler), len(datamodule.val_sampler), len(datamodule.test_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc130b3-9ea0-40eb-8bc3-e6f9186d509a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "execution": {
   "timeout": 1200
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
